{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as skmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sram/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('data/lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
       "       'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n",
       "       'is_inc_v', 'issue_d', 'loan_status', 'pymnt_plan', 'url', 'desc',\n",
       "       'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'inq_last_6mths', 'mths_since_last_delinq',\n",
       "       'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'initial_list_status', 'out_prncp',\n",
       "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv',\n",
       "       'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee',\n",
       "       'recoveries', 'collection_recovery_fee', 'last_pymnt_d',\n",
       "       'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
       "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
       "       'policy_code', 'not_compliant', 'status', 'inactive_loans',\n",
       "       'bad_loans', 'emp_length_num', 'grade_num', 'sub_grade_num',\n",
       "       'delinq_2yrs_zero', 'pub_rec_zero', 'collections_12_mths_zero',\n",
       "       'short_emp', 'payment_inc_ratio', 'final_d', 'last_delinq_none',\n",
       "       'last_record_none', 'last_major_derog_none'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x: +1 if x==0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans = loans.drop('bad_loans',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = 'safe_loans'\n",
    "features = ['grade', 'term','home_ownership','emp_length']\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grade', 'term', 'home_ownership', 'emp_length', 'safe_loans'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['grade_A' 'grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OTHER' 'home_ownership_OWN' 'home_ownership_RENT'\n",
      " 'emp_length_1 year' 'emp_length_10+ years' 'emp_length_2 years'\n",
      " 'emp_length_3 years' 'emp_length_4 years' 'emp_length_5 years'\n",
      " 'emp_length_6 years' 'emp_length_7 years' 'emp_length_8 years'\n",
      " 'emp_length_9 years' 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# one Hot encoding. \n",
    "#\n",
    "loans_ohe = pd.get_dummies(loans)\n",
    "loans_ohe.columns.values\n",
    "features = loans_ohe.columns.values\n",
    "#remove the target\n",
    "features= features[1:]\n",
    "#ohe_features = ohe_features[1:]\n",
    "print (len(features))\n",
    "print (features)\n",
    "print (type(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grade_A' 'grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OTHER' 'home_ownership_OWN' 'home_ownership_RENT'\n",
      " 'emp_length_1 year' 'emp_length_10+ years' 'emp_length_2 years'\n",
      " 'emp_length_3 years' 'emp_length_4 years' 'emp_length_5 years'\n",
      " 'emp_length_6 years' 'emp_length_7 years' 'emp_length_8 years'\n",
      " 'emp_length_9 years' 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "AFTER==== ['grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OTHER' 'home_ownership_OWN' 'home_ownership_RENT'\n",
      " 'emp_length_1 year' 'emp_length_10+ years' 'emp_length_2 years'\n",
      " 'emp_length_3 years' 'emp_length_4 years' 'emp_length_5 years'\n",
      " 'emp_length_6 years' 'emp_length_7 years' 'emp_length_8 years'\n",
      " 'emp_length_9 years' 'emp_length_< 1 year' 'emp_length_n/a']\n"
     ]
    }
   ],
   "source": [
    "print (features)\n",
    "x = np.where(features=='grade_A')\n",
    "\n",
    "features = np.delete(features,x,0)\n",
    "\n",
    "print (\"AFTER====\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# load idx files for test and train data\n",
    "#\n",
    "import json\n",
    "\n",
    "with open('data/module-8-assignment-2-test-idx.json','r') as f:\n",
    "    test_idx = json.load(f)\n",
    "f.close()\n",
    "    \n",
    "with open ('data/module-8-assignment-2-train-idx.json','r') as f:\n",
    "    train_idx = json.load(f)\n",
    "f.close()\n",
    "\n",
    "train_data=loans_ohe.iloc[train_idx]\n",
    "test_data = loans_ohe.iloc[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    # Sum the weights of all entries with label +1\n",
    "    #positive_nodes = [labels_in_node == +1]\n",
    "    #print (positive_nodes)\n",
    "    #data_weights['positive'] = positive_nodes\n",
    "    \n",
    "    #print (data_weights['positive'])\n",
    "    #total_weight_positive = sum(data_weights[data_weights['positive']==1])\n",
    "    \n",
    "    #total_weight_positive = data_weights[labels_in_node.values ==1]\n",
    "    #print (\"mistakes: columns\", data_weights.columns.values)\n",
    "    #print (\"mistakes: data weights type\", type(data_weights))\n",
    "    #print (\"mistakes: labels in node\", type(labels_in_node))\n",
    "    #print (\"*******************\")\n",
    "    #total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    #print (\"Data Wiehgt type {0}, shape {1}\", (type(data_weights), data_weights.shape))\n",
    "\n",
    "    total_weight_positive = pd.DataFrame.sum(data_weights[labels_in_node.values == +1])[0]\n",
    "    # Sum the weights of all entries with label -1\n",
    "    total_weight_negative = pd.DataFrame.sum(data_weights[labels_in_node.values == -1])[0]\n",
    "    \n",
    "    #print (\"data_weights \", len(data_weights[labels_in_node.values == +1]))\n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    # weighted_mistakes_all_negative = total_weight_positive\n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    #weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    #print (\"positve, negative\", total_weight_positive, total_weight_negative)\n",
    "    # Return the tuple (weight, class_label) representing the lower of the two weights\n",
    "    #    class_label should be an integer of value +1 or -1.\n",
    "    # If the two weights are identical, return (weighted_mistakes_all_positive,+1)\n",
    "    #print (\"mistake: positive, negative\", (weighted_mistakes_all_positive, weighted_mistakes_all_negative))\n",
    "    return (total_weight_positive, +1) if (total_weight_positive < total_weight_negative) else  (total_weight_negative,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** if alpha =1, then the classification error is the same as unboosted decision stumps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pick best feature to split on\n",
    "\n",
    "11. We continue modifying our decision tree code from the earlier assignment to incorporate weighting of individual data points. The next step is to pick the best feature to split on.\n",
    "\n",
    "The best_splitting_feature function is similar to the one from the earlier assignment with two minor modifications:\n",
    "\n",
    "The function best_splitting_feature should now accept an extra parameter data_weights to take account of weights of data points.\n",
    "Instead of computing the number of mistakes in the left and right side of the split, we compute the weight of mistakes for both sides, add up the two weights, and divide it by the total weight of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If the data is identical in each feature, this function should return None\n",
    "\n",
    "def best_splitting_feature(data,features,target, data_weights):\n",
    "    target_values = data[target]\n",
    "    best_feature = None\n",
    "    best_error = float('+inf')\n",
    "    \n",
    "    #convert to float\n",
    "    total_weight = pd.DataFrame.sum(data_weights,axis=0)[0]\n",
    "    #print (\"total weight:\", total_weight)\n",
    "    #print (type(total_weight))\n",
    "    #num_data_points = float(len(data))\n",
    "    #mfeatures = np.delete(features,0)\n",
    "    #consider each feature to decide what to split on\n",
    "    for feature in features:\n",
    "        \n",
    "        left_split = data[data[feature] == 0]        \n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "         # Apply the same filtering to data_weights to create left_data_weights, right_data_weights\n",
    "        ## YOUR CODE HERE\n",
    "        left_data_weights = data_weights[data[feature].values == 0]\n",
    "        right_data_weights = data_weights[data[feature].values== 1]\n",
    "        #left side misclassicifed\n",
    "        \n",
    "        left_weighted_mistakes,left_class = intermediate_node_weighted_mistakes(left_split,left_data_weights)\n",
    "        right_weighted_mistakes,right_class = intermediate_node_weighted_mistakes(right_split,right_data_weights)\n",
    "        \n",
    "        error = float(left_weighted_mistakes + right_weighted_mistakes)/float(total_weight)\n",
    "        #print (\"left {0} right{1} total {2}\".format(left_weighted_mistakes, right_weighted_mistakes, total_weight))\n",
    "        #print (\"error {0} feature {1}\".format(error, feature))\n",
    "        if error < best_error:\n",
    "            print (\"setting best feature to {0} for error {1}\".format(feature, error))\n",
    "            best_error = error\n",
    "            best_feature = feature\n",
    "        \n",
    "    print (\"Best Feature is %s\", best_feature)\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    \n",
    "    # Computed weight of mistakes.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    leaf['prediction'] = best_class\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    target_values = data[target]\n",
    "    print (\"--------------------------------------------------------------------\")\n",
    "    print (\"Subtree, depth, data points).\", (current_depth, len(target_values)))\n",
    "    print (\"weighted: type of data weights\", type(data_weights))\n",
    "    print (\"weighted: len of data_weights\", len(data_weights))\n",
    "    print (\"weighted: len of targets\", len(target_values))\n",
    "    \n",
    "    # Stopping condition 1. Error is 0.\n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print (\"Stopping condition 1 reached.\")               \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. No more features.\n",
    "    if remaining_features == []:\n",
    "        print (\"Stopping condition 2 reached.\")               \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth > max_depth:\n",
    "        print (\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # If all the datapoints are the same, splitting_feature will be None. Create a leaf\n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    #remaining_features.delete(splitting_feature,axis=1)\n",
    "    splitting_feature_index = np.where(remaining_features== splitting_feature)\n",
    "    #print (\"REMOVAL INDEX IS\", splitting_feature_index[0][0])\n",
    "    #print (x[0][0])\n",
    "    # delete takes the index and the axis\n",
    "    remaining_features = np.delete(remaining_features,splitting_feature_index,0)\n",
    "    print (remaining_features)\n",
    "    #x = np.where(features=='grade_A')\n",
    "    #features = np.delete(features,x,0)\n",
    "    #print (remaining_features)\n",
    "    #np.delete(remaining_features,splitting_feature,0)\n",
    "    left_split = data[data[splitting_feature].values == 0]\n",
    "    right_split = data[data[splitting_feature].values == 1]\n",
    "\n",
    "    left_data_weights = data_weights[data[splitting_feature].values == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature].values == 1]\n",
    "    #print (\"Left data weight \", type(left_data_weights))\n",
    "    \n",
    "    #print (\"Split on feature \",  (\\\n",
    "              #splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print (\"At leaf, predicting \", tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # Split on feature.\n",
    "        #print (tree['splitting_feature'])\n",
    "        #print (x)\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print (\"Split on \", (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = data.apply(lambda x: classify(tree, x), axis=1)\n",
    "    print (\"evaluation: data length is \", len(data))\n",
    "    print(\"evaluation: target len\", len(data[target]))\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error\n",
    "    return (prediction[prediction.values != data[target].values]).sum()/float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sram/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature is %s grade_B\n",
      "['grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 26858)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 26858\n",
      "weighted: len of targets 26858\n",
      "setting best feature to grade_C for error 0.35714285714285715\n",
      "Best Feature is %s grade_C\n",
      "['grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (3, 17446)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 17446\n",
      "weighted: len of targets 17446\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (3, 9412)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 9412\n",
      "weighted: len of targets 9412\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 10366)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 10366\n",
      "weighted: len of targets 10366\n",
      "setting best feature to grade_C for error 0.8333333333333334\n",
      "Best Feature is %s grade_C\n",
      "['grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "Creating leaf node.\n",
      "{'left': {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'grade_C', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'prediction': None}, 'is_leaf': False, 'splitting_feature': 'grade_B', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'prediction': None}\n"
     ]
    }
   ],
   "source": [
    "# Assign weights\n",
    "example_data_weights = pd.DataFrame([1.]*10 +[0.]*(len(train_data) -20) + [1.]*10)\n",
    "\n",
    "\n",
    "#print (example_data_weights)\n",
    "#sum = pd.DataFrame.sum(example_data_weights, axis=0)\n",
    "#print (sum[0])\n",
    "#graphlab.SArray([1.] * 10 + [0.]*(len(train_data) - 20) + [1.] * 10)\n",
    "# Train a weighted decision tree model.\n",
    "small_data_decision_tree_subset_20 = weighted_decision_tree_create(train_data, features, target,\n",
    "                         example_data_weights, max_depth=2)\n",
    "print (small_data_decision_tree_subset_20)\n",
    "#train_data[output.values==1]\n",
    "#print (small_data_decision_tree_subset_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation: data length is  37224\n",
      "evaluation: target len 37224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.225177304964539"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data.head()\n",
    "#small_data_decision_tree_subset_20['splitting_feature']\n",
    "#train_data.iloc[:,0]\n",
    "#train_data[0][small_data_decision_tree_subset_20['splitting_feature']]\n",
    "#train_data.apply(lambda x: print (x))\n",
    "evaluate_classification_error(small_data_decision_tree_subset_20,train_data)\n",
    "#train_data['grade_A'].apply(lambda x: print (x) )\n",
    "#x = small_data_decision_tree_subset_20['splitting_feature']\n",
    "#print (x)\n",
    "#print (type(small_data_decision_tree_subset_20))\n",
    "#print (small_data_decision_tree_subset_20)\n",
    "#for k in small_data_decision_tree_subset_20.keys():\n",
    "#print (small_data_decision_tree_subset_20.values(k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:\n",
    "Will you get the same model as small_data_decision_tree_subset_20 \n",
    "if you trained a decision tree with only the 20 data points with non-zero weights from the set of points in subset_20?\n",
    "**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_adjustment(elem, weight):\n",
    "    return exp(-weight) if elem == 1 else exp(weight)\n",
    "compute_adjustment = np.vectorize(compute_adjustment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # start with unweighted data\n",
    "    alpha = pd.DataFrame([1.]*len(data))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in range(num_tree_stumps):\n",
    "        print ('=====================================================')\n",
    "        print ('Adaboost Iteration %d' % t)\n",
    "        print ('=====================================================')     \n",
    "        # Learn a weighted decision tree stump. Use max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        \n",
    "        print (\"adaboost: tree stumps\", len(tree_stumps))\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x, annotate=False), axis=1)\n",
    "        \n",
    "        print (\"adaboost data len \", len(data))\n",
    "        \n",
    "        # Produce a Boolean array indicating whether\n",
    "        # each data point was correctly classified\n",
    "        print (\"adaboost: target \", len(target_values))\n",
    "        print (\"adaboost: predictions \",len(predictions))\n",
    "        is_correct = predictions.values == target_values.values\n",
    "        is_wrong   = predictions.values != target_values.values\n",
    "        print (\"adaboost :correct \", is_correct)\n",
    "        print (\"adaboost iswrong \", is_wrong)\n",
    "        print (\"adaboost type of iscorrect\", type(is_correct))\n",
    "        \n",
    "        # Compute weighted error\n",
    "        # YOUR CODE HERE\n",
    "        print (type(is_wrong))\n",
    "        weighted_error = float(is_wrong.sum())/float((is_wrong.sum()+is_correct.sum()))\n",
    "        \n",
    "        # Compute model coefficient using weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weight = 1./2.*log((1.-weighted_error)/weighted_error)\n",
    "\n",
    "        weights.append(weight)\n",
    "        #adjustment = np.apply_along_axis(is_correct.apply(lambda is_correct : exp(-weight) if is_correct else exp(weight))\n",
    "        \n",
    "        adjustment = compute_adjustment(is_correct, weight)\n",
    "        # Scale alpha by multiplying by adjustment\n",
    "        # Then normalize data points weights\n",
    "        ## YOUR CODE HERE \n",
    "        print ((alpha.shape))\n",
    "        print ((adjustment.shape))\n",
    "        alpha = alpha[0]*adjustment\n",
    "        \n",
    "        alpha_sum = alpha.sum()\n",
    "        alpha.apply(lambda x: x/alpha_sum)\n",
    "        alpha = pd.Series.to_frame(alpha)\n",
    "        print (\"final type:\", type(alpha))\n",
    "    \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37224,)\n",
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.4963464431549538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sram/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:16: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature is %s grade_B\n",
      "['grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 26858)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 26858\n",
      "weighted: len of targets 26858\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 10366)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 10366\n",
      "weighted: len of targets 10366\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 1\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [False False  True ...,  True  True  True]\n",
      "adaboost iswrong  [ True  True False ..., False False False]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.4778167834828844\n",
      "setting best feature to grade_G for error 0.47781678348288315\n",
      "setting best feature to home_ownership_OTHER for error 0.47781678348288026\n",
      "Best Feature is %s home_ownership_OTHER\n",
      "['grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 37163)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37163\n",
      "weighted: len of targets 37163\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 61)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 61\n",
      "weighted: len of targets 61\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 2\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [ True  True  True ..., False False False]\n",
      "adaboost iswrong  [False False False ...,  True  True  True]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.4815858666439044\n",
      "Best Feature is %s grade_B\n",
      "['grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 26858)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 26858\n",
      "weighted: len of targets 26858\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 10366)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 10366\n",
      "weighted: len of targets 10366\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 3\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [ True  True  True ..., False False False]\n",
      "adaboost iswrong  [False False False ...,  True  True  True]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.4852354502257628\n",
      "Best Feature is %s grade_B\n",
      "['grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 26858)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 26858\n",
      "weighted: len of targets 26858\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 10366)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 10366\n",
      "weighted: len of targets 10366\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 4\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [ True  True  True ..., False False False]\n",
      "adaboost iswrong  [False False False ...,  True  True  True]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.48888660910667286\n",
      "setting best feature to home_ownership_MORTGAGE for error 0.48888660910665654\n",
      "setting best feature to home_ownership_RENT for error 0.48888660910665155\n",
      "Best Feature is %s home_ownership_RENT\n",
      "['grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OTHER' 'home_ownership_OWN' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 20514)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 20514\n",
      "weighted: len of targets 20514\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 16710)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 16710\n",
      "weighted: len of targets 16710\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 5\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [False  True False ..., False False False]\n",
      "adaboost iswrong  [ True False  True ...,  True  True  True]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.49212007400300195\n",
      "setting best feature to grade_D for error 0.49212007400299446\n",
      "setting best feature to grade_E for error 0.4921200740029799\n",
      "setting best feature to grade_F for error 0.49212007400297597\n",
      "setting best feature to grade_G for error 0.49212007400297275\n",
      "setting best feature to home_ownership_OTHER for error 0.49212007400297136\n",
      "Best Feature is %s home_ownership_OTHER\n",
      "['grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 37163)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37163\n",
      "weighted: len of targets 37163\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 61)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 61\n",
      "weighted: len of targets 61\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 6\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [ True  True  True ..., False False False]\n",
      "adaboost iswrong  [False False False ...,  True  True  True]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.4958947598343693\n",
      "setting best feature to grade_C for error 0.49589475983435416\n",
      "setting best feature to term_ 36 months for error 0.4958947598343404\n",
      "setting best feature to home_ownership_MORTGAGE for error 0.49589475983433007\n",
      "Best Feature is %s home_ownership_MORTGAGE\n",
      "['grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 19846)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 19846\n",
      "weighted: len of targets 19846\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 17378)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 17378\n",
      "weighted: len of targets 17378\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 7\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [False False False ...,  True False False]\n",
      "adaboost iswrong  [ True  True  True ..., False  True  True]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.49373880023216343\n",
      "setting best feature to grade_C for error 0.49373880023211986\n",
      "setting best feature to grade_D for error 0.4937388002321164\n",
      "Best Feature is %s grade_D\n",
      "['grade_B' 'grade_C' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 30465)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 30465\n",
      "weighted: len of targets 30465\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 6759)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 6759\n",
      "weighted: len of targets 6759\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 8\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [ True  True  True ..., False False  True]\n",
      "adaboost iswrong  [False False False ...,  True  True False]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.520100872300897\n",
      "Best Feature is %s grade_B\n",
      "['grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G' 'term_ 36 months'\n",
      " 'term_ 60 months' 'home_ownership_MORTGAGE' 'home_ownership_OTHER'\n",
      " 'home_ownership_OWN' 'home_ownership_RENT' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 26858)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 26858\n",
      "weighted: len of targets 26858\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 10366)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 10366\n",
      "weighted: len of targets 10366\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 9\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [False False False ...,  True  True  True]\n",
      "adaboost iswrong  [ True  True  True ..., False False False]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (1, 37224)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 37224\n",
      "weighted: len of targets 37224\n",
      "setting best feature to grade_B for error 0.5237474531247018\n",
      "setting best feature to grade_C for error 0.5237474531246726\n",
      "setting best feature to home_ownership_MORTGAGE for error 0.523747453124653\n",
      "setting best feature to home_ownership_RENT for error 0.5237474531246413\n",
      "Best Feature is %s home_ownership_RENT\n",
      "['grade_B' 'grade_C' 'grade_D' 'grade_E' 'grade_F' 'grade_G'\n",
      " 'term_ 36 months' 'term_ 60 months' 'home_ownership_MORTGAGE'\n",
      " 'home_ownership_OTHER' 'home_ownership_OWN' 'emp_length_1 year'\n",
      " 'emp_length_10+ years' 'emp_length_2 years' 'emp_length_3 years'\n",
      " 'emp_length_4 years' 'emp_length_5 years' 'emp_length_6 years'\n",
      " 'emp_length_7 years' 'emp_length_8 years' 'emp_length_9 years'\n",
      " 'emp_length_< 1 year' 'emp_length_n/a']\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 20514)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 20514\n",
      "weighted: len of targets 20514\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth, data points). (2, 16710)\n",
      "weighted: type of data weights <class 'pandas.core.frame.DataFrame'>\n",
      "weighted: len of data_weights 16710\n",
      "weighted: len of targets 16710\n",
      "Reached maximum depth. Stopping for now.\n",
      "adaboost: tree stumps 10\n",
      "adaboost data len  37224\n",
      "adaboost: target  37224\n",
      "adaboost: predictions  37224\n",
      "adaboost :correct  [ True False  True ...,  True  True  True]\n",
      "adaboost iswrong  [False  True False ..., False False False]\n",
      "adaboost type of iscorrect <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(37224, 1)\n",
      "(37224,)\n",
      "final type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "alpha = pd.DataFrame([1.]*len(train_data))\n",
    "\n",
    "\n",
    "print (alpha[0].shape)\n",
    "ensemble_10 = adaboost_with_tree_stumps(train_data,features, target, num_tree_stumps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'is_leaf': False, 'splitting_feature': 'grade_B', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'home_ownership_OTHER', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'grade_B', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'grade_B', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'home_ownership_RENT', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'home_ownership_OTHER', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'is_leaf': False, 'splitting_feature': 'home_ownership_MORTGAGE', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'is_leaf': False, 'splitting_feature': 'grade_D', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'is_leaf': False, 'splitting_feature': 'grade_B', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'prediction': None}, {'left': {'is_leaf': True, 'splitting_feature': None, 'prediction': 1}, 'is_leaf': False, 'splitting_feature': 'home_ownership_RENT', 'right': {'is_leaf': True, 'splitting_feature': None, 'prediction': -1}, 'prediction': None}]\n"
     ]
    }
   ],
   "source": [
    "#print (ensemble_10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = pd.DataFrame([0.]*len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x),axis=1)\n",
    "        \n",
    "        # Accumulate predictions on scaores array\n",
    "        # YOUR CODE HERE\n",
    "        #print (predictions)\n",
    "        print (\"{0}, {1}\", (len(predictions), len(scores)))\n",
    "        scores = scores + predictions\n",
    "        \n",
    "    return scores.apply(lambda score : +1 if score.sum() > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n"
     ]
    }
   ],
   "source": [
    "score = predict_adaboost(ensemble_10[0],ensemble_10[1],train_data)\n",
    "print  (len(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37225\n",
      "37224\n"
     ]
    }
   ],
   "source": [
    "print (len(score))\n",
    "#\n",
    "# don't know why score (last prediction) has one additional entry..\n",
    "#\n",
    "score1 = score[:-1]\n",
    "#print (ensemble_10[1])\n",
    "print (len(score1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (1, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (2, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (3, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (4, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (5, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (6, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (7, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (8, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (9, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (10, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (11, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (12, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (13, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (14, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (15, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (16, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (17, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (18, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (19, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (20, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (21, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (22, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (23, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (24, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (25, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (26, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (27, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (28, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (29, 0.5036535568450462)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "{0}, {1} (37224, 37224)\n",
      "37225\n",
      "Iteration {0}, training error = {1} (30, 0.5036535568450462)\n"
     ]
    }
   ],
   "source": [
    "error_all = []\n",
    "stump_weights = ensemble_10[0]\n",
    "tree_stumps = ensemble_10[1]\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    print (len(predictions))\n",
    "    if (len(predictions) > 37224):\n",
    "        predictions = predictions[:-1]\n",
    "    error = 1.0 - skmetrics.accuracy_score(train_data[target], predictions)\n",
    "    error_all.append(error)\n",
    "    print (\"Iteration {0}, training error = {1}\", (n, error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
